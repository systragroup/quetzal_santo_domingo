{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python\n",
    "import sys\n",
    "if 'ipykernel_launcher.py' not in sys.argv[0]:\n",
    "    manual = False\n",
    "    scenario = sys.argv[1]\n",
    "# jupyter\n",
    "try: \n",
    "    scenario\n",
    "except NameError:\n",
    "    scenario = 'base'\n",
    "try: \n",
    "    manual\n",
    "except NameError:\n",
    "    manual = True\n",
    "print('manual:', manual, scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "work_path = r'../../../'\n",
    "quetzal_path = work_path + r'quetzal_santo_domingo/model/'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../quetzal/')\n",
    "\n",
    "from quetzal.model import stepmodel\n",
    "from quetzal.io import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distributed =  stepmodel.read_zip(quetzal_path + 'transport/distribution.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_frame = pd.read_csv(quetzal_path + 'parameters.csv', sep=';', decimal=',').set_index(['category','parameter'])\n",
    "for c in parameter_frame.columns:\n",
    "    parent = parameter_frame[c][('general', 'parent')]\n",
    "    parameter_frame[c] = parameter_frame[c].fillna(parameter_frame[parent])\n",
    "\n",
    "scenario_list = list(parameter_frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm =  stepmodel.read_zip(quetzal_path + 'ref_30/assigned.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.analysis_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from syspy.syspy_utils import syscolors\n",
    "plot_path = work_path + r'plot/scenarios/'\n",
    "def link_plot(sm):\n",
    "    l = gpd.GeoDataFrame(sm.links.copy()).dropna(subset=['route_type'])\n",
    "\n",
    "    d = {\n",
    "        'subway': syscolors.rainbow_shades[0],\n",
    "        'tram': syscolors.rainbow_shades[1],\n",
    "        'express_bus': syscolors.rainbow_shades[2],\n",
    "        'gondola': syscolors.rainbow_shades[3],\n",
    "        'bus': syscolors.rainbow_shades[4],\n",
    "    }\n",
    "    road_ax = sm.plot('zones', color='grey', linewidth=0.1, figsize=[17, 15])\n",
    "    for route_type, color in d.items():\n",
    "        p = l.copy()\n",
    "        p = p.loc[p['route_type'] == route_type]\n",
    "        if len(p):\n",
    "            p.plot(linewidth=5, color=color, ax=road_ax)\n",
    "        \n",
    "    plot = road_ax\n",
    "    \n",
    "    plot.set_yticks([])\n",
    "    plot.set_xticks([])\n",
    "    \n",
    "    title = 'lines_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "link_plot(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for scenario in scenario_list :\n",
    "    sm =  stepmodel.read_zip(\n",
    "        quetzal_path + scenario+  '/assigned.zip'\n",
    "    )\n",
    "    reader[scenario] = sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def revenue_stack(self, segments=('root',)):\n",
    "    df = pd.merge(self.volumes[['origin', 'destination'] + list(segments)], self.pt_los)\n",
    "    \n",
    "     \n",
    "    for segment in segments:\n",
    "        df[segment] =  df[segment] * df[(segment, 'probability')]\n",
    "\n",
    "    \n",
    "    df = df.dropna(subset=['price_breakdown'])\n",
    "    df['fare_id_tuple'] = df['fare_id_list'].apply(tuple)\n",
    "    agg_dict = {segment: 'sum' for segment in segments}\n",
    "    agg_dict['price_breakdown'] = 'first'\n",
    "    temp = df.groupby('fare_id_tuple').agg(agg_dict)\n",
    "    fare_id_set = set.union(*[set(t) for t in temp.index])\n",
    "    revenue_dict = {\n",
    "        segment :{f:0 for f in fare_id_set}\n",
    "        for segment in segments\n",
    "    }\n",
    "\n",
    "    def row_revenue(row, segment):\n",
    "        for key, value in row['price_breakdown'].items():\n",
    "            revenue_dict[segment][key] += value * row[segment]\n",
    "\n",
    "    \n",
    "    for segment in segments:\n",
    "        n = temp.apply(row_revenue, axis=1, segment=segment)\n",
    "        \n",
    "    stack = pd.DataFrame(revenue_dict).stack()\n",
    "    stack.index.names = ['fare_id', 'segment']\n",
    "    stack.name = 'sum'\n",
    "    return stack\n",
    "\n",
    "def los_stack(sm, segments=('root',)):\n",
    "    \n",
    "    left = pd.concat([sm.car_los, sm.pt_los])\n",
    "    right = sm.volumes[['origin', 'destination', 'car', 'nocar']]\n",
    "    right = pd.merge(right, sm.euclidean[['origin', 'destination', 'km']], on=['origin', 'destination'])\n",
    "    df = pd.merge(left, right, on=['origin', 'destination'])\n",
    "    \n",
    "    df.reset_index(drop=True)\n",
    "\n",
    "    df['count'] = 1\n",
    "    columns = ['time', 'km', 'in_vehicle_time', 'in_vehicle_length', 'count', 'price', 'ntransfers']\n",
    "    idf = df[['route_type']]\n",
    "\n",
    "    to_concat = []\n",
    "    for segment in segments:\n",
    "        df[(segment, 'volume')] = df[(segment, 'probability')] * df[segment]\n",
    "        pool = pd.DataFrame(\n",
    "            df[columns].apply(lambda c: c*df[(segment, 'volume')]),\n",
    "        )\n",
    "        pool.columns = [(segment, c) for c in columns]\n",
    "        to_concat.append(pool)\n",
    "        \n",
    "    idf = pd.concat([idf] + to_concat, axis=1)\n",
    "    frame = idf.fillna(0).groupby('route_type').sum().T.sort_index()\n",
    "    frame.index = pd.MultiIndex.from_tuples(frame.index)\n",
    "    frame.index.names = ['segment', 'indicator']\n",
    "\n",
    "    stack = frame.stack()\n",
    "    stack.name = 'sum'\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_sum_stack(sm, segments=('root',)):\n",
    "    \n",
    "    df = sm.loaded_links.copy()\n",
    "    columns = []\n",
    "    for segment in segments:\n",
    "        columns += [(segment, c) for c in ['boardings']]\n",
    "\n",
    "    to_concat = [\n",
    "        df[columns + ['route_type', 'route_id','trip_id'] ]]\n",
    "    \n",
    "    columns = ['length', 'time']\n",
    "    \n",
    "    for segment in segments:\n",
    "        pool = df[columns].apply(lambda c: c*df[segment])\n",
    "        pool.columns = [(segment, c) for c in columns]\n",
    "        to_concat.append(pool)\n",
    "        \n",
    "    idf = pd.concat(to_concat, axis=1)\n",
    "\n",
    "    g = idf.groupby(['route_type', 'route_id','trip_id']).sum()\n",
    "    g.columns = pd.MultiIndex.from_tuples(g.columns)\n",
    "    stack = g.stack().stack()\n",
    "    stack.index.names = ['route_type', 'route_id','trip_id', 'indicator', 'segment']\n",
    "    stack.name = 'sum'\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_max_stack(sm, segments=('root')):\n",
    "    df = sm.loaded_links\n",
    "    stack = df[\n",
    "        ['route_type', 'route_id','trip_id'] + segments\n",
    "    ].groupby(['route_type', 'route_id','trip_id']).max().stack()\n",
    "    stack.index.names = ['route_type', 'route_id','trip_id', 'segment']\n",
    "    stack.name = 'max'\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%snakeviz revenue_stack(sm, ['car', 'nocar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for scenario, sm in reader.items():\n",
    "    sm.volumes = distributed.volumes.copy()\n",
    "    sm.euclidean = distributed.euclidean\n",
    "    sm.volumes.loc[sm.volumes['origin'] == sm.volumes['destination'], ['car', 'nocar']] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacks = {}\n",
    "\n",
    "to_concat = []\n",
    "for scenario, sm in tqdm(reader.items()):\n",
    "\n",
    "    s = revenue_stack(sm, ['car', 'nocar'])\n",
    "    df = pd.DataFrame(s)\n",
    "    df['scenario'] = scenario\n",
    "    to_concat.append(df)\n",
    "\n",
    "stacks['revenues'] = pd.concat(to_concat).set_index('scenario', append=True).sort_index()[s.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_concat = []\n",
    "for scenario, sm in tqdm(reader.items()):\n",
    "\n",
    "    s = link_sum_stack(sm, ['car', 'nocar'])\n",
    "    df = pd.DataFrame(s)\n",
    "    df['scenario'] = scenario\n",
    "    to_concat.append(df)\n",
    "\n",
    "stacks['link_sum'] = pd.concat(to_concat).set_index('scenario', append=True).sort_index()[s.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_concat = []\n",
    "for scenario, sm in tqdm(reader.items()):\n",
    "\n",
    "    s = link_max_stack(sm, ['car', 'nocar'])\n",
    "    df = pd.DataFrame(s)\n",
    "    df['scenario'] = scenario\n",
    "    to_concat.append(df)\n",
    "\n",
    "stacks['link_max'] = pd.concat(to_concat).set_index('scenario', append=True).sort_index()[s.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_concat = []\n",
    "for scenario, sm in tqdm(reader.items()):\n",
    "    s = los_stack(sm, ['car', 'nocar'])\n",
    "    df = pd.DataFrame(s)\n",
    "    df['scenario'] = scenario\n",
    "    to_concat.append(df)\n",
    "\n",
    "stacks['path_sum'] = pd.concat(to_concat).set_index('scenario', append=True).sort_index()[s.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = work_path + 'data/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def densify(series):\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        series.index.levels,\n",
    "        names=series.index.names\n",
    "    )\n",
    "    dense = pd.Series(np.nan, index).fillna(series).fillna(0)\n",
    "    dense.name=series.name\n",
    "    return dense\n",
    "\n",
    "for name in 'revenues', 'path_sum':\n",
    "    stacks[name] = densify(stacks[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = stacks['path_sum']\n",
    "us = s.unstack('indicator')\n",
    "us = us.apply(lambda c: c/us['count'])\n",
    "dense = us.fillna(0).stack()\n",
    "dense.name = 'average'\n",
    "stacks['path_average'] = dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregated_path_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = stacks['path_sum'].reset_index()\n",
    "pt_route_types = list(set(stack['route_type']) - {'car', 'walk'})\n",
    "stack['route_type'] = stack['route_type'].apply(lambda rt: 'pt' if rt in pt_route_types else rt)\n",
    "\n",
    "total = stack.groupby(\n",
    "    ['scenario', 'route_type', 'indicator']\n",
    ").sum()\n",
    "\n",
    "us = total['sum'].unstack('indicator')\n",
    "share = (us['count'].unstack('scenario') / us['count'].unstack('scenario').sum()).stack().swaplevel()\n",
    "us = us.apply(lambda c: c/us['count'])\n",
    "us['share'] = share\n",
    "stack = us.stack()\n",
    "stack.name = 'average'\n",
    "stacks['aggregated_path_average'] = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely import geometry\n",
    "def buffer_stack(sm):\n",
    "    sm = sm.copy()\n",
    "    r = range(1,11)\n",
    "    \n",
    "    heavy_nodes = set(sm.links.loc[sm.links['route_type'].isin(['subway', 'tram', 'express_bus', 'gondola'])]['a'])\n",
    "    for b in r:\n",
    "        buffer = geometry.MultiPoint(list(sm.nodes.loc[heavy_nodes]['geometry'])).buffer(b * 100)\n",
    "\n",
    "        def in_buffer_ratio(geometry):\n",
    "            return (geometry.intersection(buffer).area) / geometry.area\n",
    "\n",
    "        sm.zones['ib' + str(b * 100)] = sm.zones['geometry'].apply(in_buffer_ratio)\n",
    "    right = sm.zones[['ib' + str(b * 100) for b in r]].apply(lambda c: c*sm.zones['pop'])\n",
    "    right.columns = [i * 100 for i in list(r)]\n",
    "    \n",
    "    tot = sm.zones['pop'].sum()\n",
    "    s = right.sum() / tot\n",
    "    s.name = 'ratio'\n",
    "    s.index.name = 'distance'\n",
    "    return s\n",
    "\n",
    "to_concat = []\n",
    "for scenario, sm in tqdm(reader.items()):\n",
    "\n",
    "    s = buffer_stack(sm)\n",
    "    df = pd.DataFrame(s)\n",
    "    df['scenario'] = scenario\n",
    "    to_concat.append(df)\n",
    "\n",
    "stacks['buffer'] = pd.concat(to_concat).set_index('scenario', append=True).sort_index()[s.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_frame.columns.name = 'scenario'\n",
    "parameter_stack = parameter_frame.stack()\n",
    "parameter_stack.name = 'value'\n",
    "stacks['parameters'] =  parameter_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "file = quetzal_path + 'stacks.xlsx'\n",
    "i = 0\n",
    "for name, stack in stacks.items():\n",
    "    if i == 0:\n",
    "        with pd.ExcelWriter(file, engine='openpyxl') as writer:\n",
    "            stack.reset_index().to_excel(writer, sheet_name=name, index=False)\n",
    "            writer.save()\n",
    "        book = load_workbook(file)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file, engine='openpyxl') as writer:\n",
    "\n",
    "            writer.book = book\n",
    "            stack.reset_index().to_excel(\n",
    "                writer, sheet_name=name, index=False)\n",
    "            writer.save()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = sm.pt_los.loc[sm.pt_los['all_walk'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = stacks['aggregated_path_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacks['revenues'].unstack('scenario').astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.round(s.loc[:,:, 'share',].unstack('scenario'), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "stacks['buffer'].unstack('scenario').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sm.plot('links')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggegated_path_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "road_ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from syspy.syspy_utils import data_visualization as dv\n",
    "spectral = list(reversed(['#9e0142','#d53e4f','#f46d43','#fdae61','#fee08b','#e6f598','#abdda4','#66c2a5','#3288bd','#5e4fa2']))\n",
    "\n",
    "from shapely import geometry\n",
    "def bandwidth(df, value, power=1, scale=1, legend_values=None, cmap=spectral, dynamic_width=True, *args, **kwargs):\n",
    "    color = value\n",
    "    width = value\n",
    "    \n",
    "    if legend_values is None:\n",
    "        s = df[value].copy()\n",
    "        r = int(np.log10(s.mean())) \n",
    "        legend_values = [np.round(s.quantile(i/5), -r) for i in range(6)]\n",
    "    \n",
    "    df = df[[value, 'geometry']].copy().fillna(0)\n",
    "    df = df.loc[df[value] > 0]\n",
    "    mls = geometry.MultiPoint(list(df['geometry'].apply(lambda g: g.centroid)))\n",
    "\n",
    "    b = mls.bounds\n",
    "    delta = b[2] - b[0]\n",
    "    rank = 0\n",
    "    dx = delta /4 / len(legend_values)\n",
    "    data = []\n",
    "    for v in reversed(legend_values):\n",
    "        g = geometry.LineString([\n",
    "            ( b[2] - rank * dx, (b[1] + b[1]) / 2),\n",
    "            ( b[2] - (rank + 1)*dx, (b[1] + b[1]) / 2)]\n",
    "        )\n",
    "        rank += 1\n",
    "        data.append([v, g, str(v)])\n",
    "        to_concat = pd.DataFrame(data, columns=[value, 'geometry', 'label'])\n",
    "    df = pd.concat([df, to_concat])\n",
    "    \n",
    "    df = df.loc[df[width] > 0]\n",
    "    plot = gpd.GeoDataFrame(df).plot(linewidth=0.1, color='grey', *args, **kwargs)\n",
    "    \n",
    "    power_series = (np.power(df[color], power))\n",
    "    max_value = power_series.max()\n",
    "    \n",
    "    df['color'] = dv.color_series(\n",
    "        power_series,\n",
    "        colors=spectral, \n",
    "        max_value=max_value\n",
    "    )\n",
    "    df['width'] = dv.width_series(\n",
    "        power_series, \n",
    "        outer_average_width=5, \n",
    "        max_value=max_value\n",
    "    )\n",
    "    ratio = len(spectral) / (df['width'].max() + 0.5)\n",
    "    df['cat'] = round(df['width'] * ratio).fillna(0)\n",
    "    df = df.loc[df['cat']> 0]\n",
    "\n",
    "    plot.set_yticks([])\n",
    "    plot.set_xticks([])\n",
    "    \n",
    "    for cat in set(df['cat']):\n",
    "        linewidth = cat*scale if dynamic_width else scale\n",
    "        pool = df.loc[df['cat'] == cat]\n",
    "        plot = gpd.GeoDataFrame(pool).plot(linewidth=linewidth, ax=plot, color=spectral[int(cat)]) \n",
    "       \n",
    "\n",
    "    to_concat.apply(\n",
    "        lambda x: plot.annotate(\n",
    "            s=x[value], xy=x.geometry.centroid.coords[0], ha='center', va='bottom'\n",
    "        ),axis=1\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temps moyen TC pondéré par zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scenario = 'ref_30'\n",
    "sm = reader[scenario].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_plot(scenario):\n",
    "    sm = reader[scenario].copy()\n",
    "    l = gpd.GeoDataFrame(sm.links.copy()).dropna(subset=['route_type'])\n",
    "\n",
    "    d = {\n",
    "        'subway': syscolors.rainbow_shades[0],\n",
    "        'tram': syscolors.rainbow_shades[1],\n",
    "        'express_bus': syscolors.rainbow_shades[2],\n",
    "        'gondola': syscolors.rainbow_shades[3],\n",
    "    }\n",
    "    road_ax = sm.plot('road_links', color='grey', linewidth=0.1, figsize=[17, 15])\n",
    "    for route_type, color in d.items():\n",
    "        p = l.copy()\n",
    "        p = p.loc[p['route_type'] == route_type]\n",
    "        if len(p):\n",
    "            p.plot(linewidth=5, color=color, ax=road_ax)\n",
    "        \n",
    "    plot = road_ax\n",
    "    \n",
    "    plot.set_yticks([])\n",
    "    plot.set_xticks([])\n",
    "    \n",
    "    title = 'lines_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_path = work_path + r'plot/scenarios/'\n",
    "for scenario in scenario_list:\n",
    "    link_plot(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm = reader[scenario].copy()\n",
    "left = pd.concat([sm.car_los, sm.pt_los])\n",
    "right = sm.volumes[['origin', 'destination', 'car', 'nocar']]\n",
    "\n",
    "df = pd.merge(left, right, on=['origin', 'destination'])\n",
    "df = pd.merge(df, sm.euclidean[['origin', 'destination', 'km']], on=['origin', 'destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['route_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_path = work_path + r'plot/scenarios/'\n",
    "\n",
    "def time_plot(scenario):\n",
    "    sm = reader[scenario].copy()\n",
    "    left = pd.concat([sm.car_los, sm.pt_los])\n",
    "    right = sm.volumes[['origin', 'destination', 'car', 'nocar']]\n",
    "\n",
    "    df = pd.merge(left, right, on=['origin', 'destination'])\n",
    "    df = pd.merge(df, sm.euclidean[['origin', 'destination', 'km']], on=['origin', 'destination'])\n",
    "\n",
    "    for segment in ['car', 'nocar']:\n",
    "        df[(segment, 'volume')] = df[segment]*df[(segment, 'probability')].fillna(0)\n",
    "\n",
    "    def time(zone, segment):\n",
    "        pool = df.loc[df['origin'] == zone]\n",
    "        if segment == 'car':\n",
    "            pool = pool.loc[pool['route_type'] == 'car']\n",
    "        try:\n",
    "            return np.average(pool['time'], weights=pool[(segment, 'volume')])\n",
    "        except ZeroDivisionError:\n",
    "            return np.nan\n",
    "    zones = sm.zones.copy()\n",
    "    for segment in ['car', 'nocar']:\n",
    "        zones[(segment, 'time')] = zones['index'].apply(lambda z: time(z, segment)) / 60\n",
    "    zones[('delta', 'time')] = zones[('nocar', 'time')] - zones[('car', 'time')]\n",
    "    \n",
    "    \n",
    "\n",
    "    lv = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100 ]\n",
    "\n",
    "    plot = bandwidth(zones, value=('car','time'), power=1, figsize=[17, 15], legend_values=lv, dynamic_width=False, scale=25)\n",
    "    title = 'average_time_car_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')\n",
    "\n",
    "    plot = bandwidth(zones, value=('nocar','time'), power=1, figsize=[17, 15], legend_values=lv, dynamic_width=False, scale=25)\n",
    "\n",
    "    title = 'average_time_nocar_%s' % scenario\n",
    "\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')\n",
    "\n",
    "    lv = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "    plot = bandwidth(zones, value=('delta','time'), power=1, figsize=[17, 15], legend_values=lv, dynamic_width=False, scale=25)\n",
    "    title = 'average_time_delta_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def share_plot(scenario):\n",
    "    \n",
    "    sm = reader[scenario].copy()\n",
    "    zones = sm.zones.copy()\n",
    "    \n",
    "    left = pd.concat([sm.car_los, sm.pt_los])\n",
    "    right = sm.volumes[['origin', 'destination', 'car', 'nocar']]\n",
    "\n",
    "    df = pd.merge(left, right, on=['origin', 'destination'])\n",
    "    df = pd.merge(df, sm.euclidean[['origin', 'destination', 'km']], on=['origin', 'destination'])\n",
    "    for segment in ['car', 'nocar']:\n",
    "        df[(segment, 'volume')] = df[segment]*df[(segment, 'probability')].fillna(0)\n",
    "\n",
    "    df[('root', 'volume')] = df[('car', 'volume')] + df[('nocar', 'volume')]\n",
    "    osum = df.groupby(['origin']).sum()[('car', 'volume')]\n",
    "    mat = df.groupby(['origin', 'route_type']).sum()[('car', 'volume')].unstack('route_type')\n",
    "    zones['car_car_share'] = mat.apply(lambda s: s/osum)['car']\n",
    "    lv = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    plot = bandwidth(zones, value='car_car_share', power=4, figsize=[17, 15], legend_values=lv, dynamic_width=False, scale=25)\n",
    "\n",
    "    title = 'car_share_among_car_owners_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')\n",
    "\n",
    "    osum = df.groupby(['origin']).sum()[('root', 'volume')]\n",
    "    mat = df.groupby(['origin', 'route_type']).sum()[('root', 'volume')].unstack('route_type')\n",
    "    \n",
    "    \n",
    "    zones['root_car_share'] = mat.apply(lambda s: s/osum)['car']\n",
    "    lv = [0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    plot = bandwidth(zones, value='root_car_share', power=1, figsize=[17, 15], legend_values=lv, dynamic_width=False, scale=25)\n",
    "    title = 'car_share_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')\n",
    "\n",
    "def loaded_plot(scenario):\n",
    "    sm = reader[scenario].copy()\n",
    "    \n",
    "    lv = (15000, 10000, 7000,  5000, 3500, 2000, 1000)\n",
    "\n",
    "    i_links = sm.loaded_links.loc[sm.loaded_links.road_length.isnull()]\n",
    "    df = pd.concat([i_links, sm.road_links])\n",
    "    columns = [('nocar', 'pt'), ('car', 'pt'), ('car', 'car'), 'geometry']\n",
    "    df['pt'] = df[('nocar', 'pt')] +df[ ('car', 'pt')]\n",
    "    df = df.loc[df['pt'] > 0]\n",
    "\n",
    "    road_ax = sm.plot('road_links', color='grey', linewidth=0.1, figsize=[17, 15])\n",
    "    plot = bandwidth(df, value='pt', power=0.5, figsize=[17, 15], legend_values=lv, ax=road_ax)\n",
    "\n",
    "    title = 'loaded_%s' % scenario\n",
    "    plot.set_title(title)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(plot_path + title + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = stacks['aggregated_path_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.loc[:,'pt', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scenario in scenario_list:\n",
    "    loaded_plot(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scenario in scenario_list:\n",
    "    time_plot(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for scenario in scenario_list:\n",
    "    share_plot(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = sm.loaded_links\n",
    "l = sm.loaded_links.loc[sm.loaded_links['route_type_group'] == 'heavy']\n",
    "plot = sm.plot('zones', color='white',edgecolor='black',linewidth=0.5,  figsize=[17, 15])\n",
    "\n",
    "sm.zones['label'] = sm.zones['index'].apply(lambda x: x.split('_')[1])\n",
    "sm.zones.apply(\n",
    "    lambda x: plot.annotate(\n",
    "        s=x['label'], xy=x.geometry.centroid.coords[0], ha='center', va='bottom', fontsize=10\n",
    "    ),axis=1\n",
    ")\n",
    "%matplotlib inline\n",
    "\n",
    "bandwidth(l, 'nocar',  power=1, ax=plot, scale=1, legend_values=lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "projected = sm.change_epsg(epsg=4326, coordinates_unit='degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display.all_pt_paths(projected,'zone_144', 'zone_98', color_column='route_color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.links['route_color'] = sm.links['route_color'].apply(lambda c: c if '#' in c else '#' + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lp = sm.pt_los.set_index(['origin', 'destination']).loc['zone_144', 'zone_98'].iloc[0]['link_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gpd.GeoDataFrame(sm.links.loc[lp]).plot(ax=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm.links.loc[lp]['route_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm = reader['centro_30']\n",
    "l = sm.loaded_links.loc[sm.loaded_links['route_type_group'] == 'heavy']\n",
    "l.loc[l['route_id'] == '27_febrero']['route_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
